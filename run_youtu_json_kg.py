#!/usr/bin/env python3
"""
ä¸“é—¨é’ˆå¯¹ youtu-graphrag JSON æ ¼å¼çš„å®Œæ•´è¿è¡Œè„šæœ¬
"""

import os
import sys
import time
import argparse
import json
from pathlib import Path

# é¦–å…ˆå°è¯•åº”ç”¨ nest_asyncio æ¥è§£å†³äº‹ä»¶å¾ªç¯é—®é¢˜
try:
    import nest_asyncio
    nest_asyncio.apply()
    print("âœ… nest_asyncio å·²åº”ç”¨ï¼Œè§£å†³äº‹ä»¶å¾ªç¯åµŒå¥—é—®é¢˜")
except ImportError:
    print("âš ï¸  nest_asyncio æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install nest_asyncio")
    print("å°†ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼Œä½†å¯èƒ½ä¼šé‡åˆ°äº‹ä»¶å¾ªç¯é—®é¢˜")

try:
    from dotenv import load_dotenv
except ImportError:
    print("âš ï¸  python-dotenv æœªå®‰è£…ï¼Œè·³è¿‡ .env æ–‡ä»¶åŠ è½½")
    def load_dotenv():
        pass

# æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from youtu_json_converter import YoutuJSONConverter
except ImportError as e:
    print(f"âš ï¸  youtu_json_converter å¯¼å…¥å¤±è´¥: {e}")
    print("ä½¿ç”¨ç®€åŒ–ç‰ˆè½¬æ¢å™¨...")
    try:
        from simple_youtu_converter import SimpleYoutuConverter as YoutuJSONConverter
    except ImportError:
        print("âŒ ç®€åŒ–ç‰ˆè½¬æ¢å™¨ä¹Ÿä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶")
        sys.exit(1)

try:
    from custom_graphgen import CustomGraphGen, create_custom_config
    from graphgen.utils import logger, set_logger
    GRAPHGEN_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸  GraphGen å¯¼å…¥å¤±è´¥: {e}")
    print("å°†ä½¿ç”¨ç®€åŒ–ç‰ˆç”Ÿæˆæ–¹æ¡ˆ...")
    GRAPHGEN_AVAILABLE = False
    
    # åˆ›å»ºç®€å•çš„æ—¥å¿—å‡½æ•°
    class SimpleLogger:
        def info(self, msg): print(f"INFO: {msg}")
        def warning(self, msg): print(f"WARNING: {msg}")
        def error(self, msg): print(f"ERROR: {msg}")
    
    logger = SimpleLogger()
    def set_logger(file, if_stream=True): pass


def setup_environment(disable_quiz: bool = False):
    """è®¾ç½®ç¯å¢ƒ"""
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡
    required_vars = ['SYNTHESIZER_MODEL', 'SYNTHESIZER_API_KEY', 'SYNTHESIZER_BASE_URL']
    
    # å¦‚æœæ²¡æœ‰ç¦ç”¨ quizï¼Œåˆ™éœ€è¦ TRAINEE ç›¸å…³å˜é‡
    if not disable_quiz:
        required_vars.extend(['TRAINEE_MODEL', 'TRAINEE_API_KEY', 'TRAINEE_BASE_URL'])
    
    missing_vars = []
    for var in required_vars:
        if not os.getenv(var):
            missing_vars.append(var)
    
    if missing_vars:
        print(f"âŒ ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®è¿™äº›å˜é‡")
        print("\nç¤ºä¾‹ .env æ–‡ä»¶å†…å®¹:")
        print("SYNTHESIZER_MODEL=gpt-4")
        print("SYNTHESIZER_API_KEY=your_api_key")
        print("SYNTHESIZER_BASE_URL=https://api.openai.com/v1")
        if not disable_quiz:
            print("TRAINEE_MODEL=gpt-3.5-turbo")
            print("TRAINEE_API_KEY=your_api_key")
            print("TRAINEE_BASE_URL=https://api.openai.com/v1")
        else:
            print("# TRAINEE ç›¸å…³å˜é‡åœ¨ç¦ç”¨ quiz æ—¶ä¸æ˜¯å¿…éœ€çš„")
        return False
    
    return True


def convert_youtu_json_kg(json_file: str, output_file: str, stats_file: str = None):
    """è½¬æ¢ youtu-graphrag JSON çŸ¥è¯†å›¾è°±"""
    print("ğŸ”„ å¼€å§‹è½¬æ¢ youtu-graphrag JSON çŸ¥è¯†å›¾è°±...")
    
    try:
        converter = YoutuJSONConverter()
        data = converter.load_youtu_json_data(json_file)
        converter.parse_youtu_data(data)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ GraphML ä¿å­˜æ–¹æ³•
        if hasattr(converter, 'save_to_graphml'):
            converter.convert_to_graphgen_format()
            if hasattr(converter, 'validate_graph'):
                converter.validate_graph()
            converter.save_to_graphml(output_file)
        else:
            # ä½¿ç”¨ç®€åŒ–ç‰ˆçš„ JSON ä¿å­˜
            converter.save_to_json(output_file.replace('.graphml', '.json'))
        
        if stats_file and hasattr(converter, 'export_statistics'):
            converter.export_statistics(stats_file)
        
        return True
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def run_graphgen_with_youtu_json(
    json_file: str = None,
    external_graph_path: str = None,
    working_dir: str = "cache",
    generation_mode: str = "atomic",
    data_format: str = "Alpaca",
    quiz_samples: int = 5,
    disable_quiz: bool = False,
    max_depth: int = 3,
    max_extra_edges: int = 5,
    enable_search: bool = False,
    skip_convert: bool = False
):
    """ä½¿ç”¨ youtu-graphrag JSON çŸ¥è¯†å›¾è°±è¿è¡Œ GraphGen"""
    
    # å¦‚æœ GraphGen ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæ–¹æ¡ˆ
    if not GRAPHGEN_AVAILABLE:
        return await run_simplified_generation(
            json_file, working_dir, generation_mode, data_format
        )
    
    return await run_full_graphgen(
        json_file, external_graph_path, working_dir, generation_mode, 
        data_format, quiz_samples, disable_quiz, max_depth, 
        max_extra_edges, enable_search, skip_convert
    )


async def run_simplified_generation(
    json_file: str,
    working_dir: str = "cache",
    generation_mode: str = "atomic", 
    data_format: str = "Alpaca"
):
    """ç®€åŒ–ç‰ˆç”Ÿæˆæ–¹æ¡ˆ"""
    print("ğŸš€ ä½¿ç”¨ç®€åŒ–ç‰ˆç”Ÿæˆæ–¹æ¡ˆ...")
    
    try:
        # 1. è½¬æ¢æ•°æ®
        print("ğŸ“ æ­¥éª¤1: è½¬æ¢çŸ¥è¯†å›¾è°±æ•°æ®...")
        converter = YoutuJSONConverter()
        data = converter.load_youtu_json_data(json_file)
        converter.parse_youtu_data(data)
        
        converted_file = os.path.join(working_dir, "converted_data.json")
        result = converter.save_to_json(converted_file)
        
        # 2. ç”Ÿæˆé—®ç­”å¯¹
        print("âš¡ æ­¥éª¤2: ç”Ÿæˆé—®ç­”æ•°æ®...")
        from create_qa_from_converted import create_qa_from_converted_data
        
        qa_pairs = create_qa_from_converted_data(converted_file, data_format)
        
        # 3. ä¿å­˜ç»“æœ
        unique_id = int(time.time())
        output_dir = os.path.join(working_dir, "data", "graphgen", str(unique_id))
        os.makedirs(output_dir, exist_ok=True)
        
        output_file = os.path.join(output_dir, "qa.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(qa_pairs, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… ç®€åŒ–ç‰ˆæ•°æ®ç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ“„ ç”Ÿæˆæ–‡ä»¶: qa.json")
        print(f"ğŸ“Š é—®ç­”å¯¹æ•°é‡: {len(qa_pairs)}")
        
        # æ˜¾ç¤ºç¤ºä¾‹
        print(f"\nğŸ“ ç¤ºä¾‹é—®ç­”å¯¹:")
        for i, qa in enumerate(qa_pairs[:3]):
            print(f"{i+1}. Q: {qa.get('instruction', qa.get('conversations', [{}])[0].get('value', 'N/A'))}")
            if 'output' in qa:
                print(f"   A: {qa['output']}")
            elif 'conversations' in qa and len(qa['conversations']) > 1:
                print(f"   A: {qa['conversations'][1].get('value', 'N/A')}")
            print()
        
        return True
        
    except Exception as e:
        print(f"âŒ ç®€åŒ–ç‰ˆç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def run_full_graphgen(
    json_file: str = None,
    external_graph_path: str = None,
    working_dir: str = "cache",
    generation_mode: str = "atomic",
    data_format: str = "Alpaca",
    quiz_samples: int = 5,
    disable_quiz: bool = False,
    max_depth: int = 3,
    max_extra_edges: int = 5,
    enable_search: bool = False,
    skip_convert: bool = False
):
    """ä½¿ç”¨ youtu-graphrag JSON çŸ¥è¯†å›¾è°±è¿è¡Œ GraphGen"""
    
    print(f"ğŸš€ å¼€å§‹ä½¿ç”¨ youtu-graphrag JSON çŸ¥è¯†å›¾è°±ç”Ÿæˆæ•°æ®...")
    
    # ç¡®å®šå›¾è°±æ–‡ä»¶è·¯å¾„
    if not external_graph_path:
        external_graph_path = os.path.join(working_dir, "youtu_graph.graphml")
    
    # å¦‚æœéœ€è¦è½¬æ¢ä¸”æä¾›äº† JSON æ–‡ä»¶
    if not skip_convert and json_file:
        stats_file = os.path.join(working_dir, "youtu_graph_stats.json")
        if not convert_youtu_json_kg(json_file, external_graph_path, stats_file):
            return False
    
    # æ£€æŸ¥å›¾è°±æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(external_graph_path):
        print(f"âŒ çŸ¥è¯†å›¾è°±æ–‡ä»¶ä¸å­˜åœ¨: {external_graph_path}")
        return False
    
    print(f"ğŸ“ ä½¿ç”¨çŸ¥è¯†å›¾è°±: {external_graph_path}")
    print(f"ğŸ“ å·¥ä½œç›®å½•: {working_dir}")
    print(f"ğŸ¯ ç”Ÿæˆæ¨¡å¼: {generation_mode}")
    print(f"ğŸ“„ æ•°æ®æ ¼å¼: {data_format}")
    
    # åˆ›å»ºé…ç½®
    config = create_custom_config(
        external_graph_path=external_graph_path,
        generation_mode=generation_mode,
        data_format=data_format,
        quiz_samples=quiz_samples if not disable_quiz else 0,
        max_depth=max_depth,
        max_extra_edges=max_extra_edges
    )
    
    # å¦‚æœç¦ç”¨ quiz æˆ– quiz_samples ä¸º 0ï¼Œåˆ™ç¦ç”¨é—®ç­”æµ‹è¯•
    if disable_quiz or quiz_samples == 0:
        config["quiz_and_judge"]["enabled"] = False
        # åŒæ—¶å°†edge_samplingæ”¹ä¸ºrandomï¼Œå› ä¸ºæ²¡æœ‰losså±æ€§
        if (config["partition"]["method"] == "ece" 
            and "method_params" in config["partition"]):
            config["partition"]["method_params"]["edge_sampling"] = "random"
        print("â­ï¸  é—®ç­”æµ‹è¯•å’Œåˆ¤æ–­å·²ç¦ç”¨")
        print("â­ï¸  è¾¹é‡‡æ ·ç­–ç•¥å·²è®¾ä¸º randomï¼ˆå› ä¸ºæ²¡æœ‰losså±æ€§ï¼‰")
    
    # å¦‚æœå¯ç”¨æœç´¢ï¼Œæ›´æ–°é…ç½®
    if enable_search:
        config["search"]["enabled"] = True
        config["search"]["search_types"] = ["google"]
    
    # è®¾ç½®æ—¥å¿—
    unique_id = int(time.time())
    log_file = os.path.join(working_dir, f"youtu_json_kg_{unique_id}_{generation_mode}.log")
    set_logger(log_file, if_stream=True)
    
    # åˆ›å»ºè‡ªå®šä¹‰ GraphGen å®ä¾‹ï¼ˆæ— traineeæ¨¡å¼ï¼‰
    graph_gen = CustomGraphGen(
        external_graph_path=external_graph_path,
        working_dir=working_dir,
        unique_id=unique_id,
        skip_kg_building=True,
        no_trainee_mode=True  # å¯ç”¨æ— traineeæ¨¡å¼
    )
    
    # æ˜¾ç¤ºå½“å‰é…ç½®çŠ¶æ€
    print("\nğŸ”§ å½“å‰é…ç½®çŠ¶æ€:")
    print(f"   ğŸ“‹ æ— traineeæ¨¡å¼: âœ… å¯ç”¨")
    print(f"   ğŸ—ï¸  è·³è¿‡KGæ„å»º: {'âœ… å¯ç”¨' if graph_gen.skip_kg_building else 'âŒ ç¦ç”¨'}")
    print(f"   ğŸ¤– Synthesizerå®¢æˆ·ç«¯: {'âœ… å¯ç”¨' if graph_gen.synthesizer_llm_client else 'âŒ ä¸å¯ç”¨'}")
    print(f"   ğŸ“ Traineeå®¢æˆ·ç«¯: {'âœ… å¯ç”¨' if graph_gen.trainee_llm_client else 'âŒ ä¸å¯ç”¨'}")
    print(f"   ğŸ“Š å¤–éƒ¨å›¾è°±: {'âœ… å·²åŠ è½½' if graph_gen.external_graph_path else 'âŒ æœªåŠ è½½'}")
    
    if not graph_gen.synthesizer_llm_client:
        print("\nâš ï¸  æ³¨æ„ï¼šsynthesizerå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        print("   ğŸ’¡ å¦‚éœ€å®Œæ•´åŠŸèƒ½ï¼Œè¯·è®¾ç½®: export SYNTHESIZER_API_KEY='your_openai_api_key'")
        print("   ğŸ”„ å°†è‡ªåŠ¨ä½¿ç”¨ç®€åŒ–ç‰ˆç”Ÿæˆæ–¹æ¡ˆ")
    
    try:
        # æ­¥éª¤1: åˆå§‹åŒ–å¤–éƒ¨çŸ¥è¯†å›¾è°±
        print("ğŸ“ æ­¥éª¤1: åˆå§‹åŒ–å¤–éƒ¨çŸ¥è¯†å›¾è°±...")
        await graph_gen.insert(
            read_config=config["read"], 
            split_config=config["split"]
        )
        
        # æ˜¾ç¤ºå›¾è°±æ‘˜è¦
        summary = graph_gen.get_graph_summary()
        print(f"\nğŸ“Š çŸ¥è¯†å›¾è°±æ‘˜è¦:")
        print(f"   - èŠ‚ç‚¹æ•°: {summary['nodes']}")
        print(f"   - è¾¹æ•°: {summary['edges']}")
        print(f"   - å›¾å¯†åº¦: {summary['density']:.4f}")
        print(f"   - è¿é€šç»„ä»¶: {summary.get('connected_components', 'N/A')}")
        
        if 'node_types' in summary:
            print(f"   - èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒ:")
            for node_type, count in sorted(summary['node_types'].items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"     * {node_type}: {count}")
        
        # æ­¥éª¤2: å¯é€‰çš„æœç´¢å¢å¼º
        if config["search"]["enabled"]:
            print("ğŸ” æ­¥éª¤2: æœç´¢å¢å¼º...")
            graph_gen.search(search_config=config["search"])
        else:
            print("â­ï¸  æ­¥éª¤2: è·³è¿‡æœç´¢å¢å¼º")
        
        # æ­¥éª¤3: é—®ç­”æµ‹è¯•å’Œåˆ¤æ–­
        if config["quiz_and_judge"]["enabled"]:
            print("ğŸ§  æ­¥éª¤3: é—®ç­”æµ‹è¯•å’Œåˆ¤æ–­...")
            graph_gen.quiz_and_judge(quiz_and_judge_config=config["quiz_and_judge"])
        else:
            print("â­ï¸  æ­¥éª¤3: è·³è¿‡é—®ç­”æµ‹è¯•å’Œåˆ¤æ–­ï¼ˆå·²ç¦ç”¨ï¼‰")
        
        # æ­¥éª¤4: ç”Ÿæˆæ•°æ®
        print(f"âš¡ æ­¥éª¤4: ç”Ÿæˆ {generation_mode} æ•°æ®...")
        try:
            # ä½¿ç”¨åŒæ­¥è°ƒç”¨ï¼Œå› ä¸ºè¢«@async_to_sync_methodè£…é¥°çš„æ–¹æ³•å®é™…ä¸Šæ˜¯åŒæ­¥çš„
            graph_gen.generate(
                partition_config=config["partition"],
                generate_config=config["generate"]
            )
        except ValueError as e:
            if "synthesizer_llm_client æœªåˆå§‹åŒ–" in str(e):
                logger.error(f"âŒ æ— traineeæ¨¡å¼éœ€è¦synthesizerå®¢æˆ·ç«¯: {e}")
                logger.warning("ğŸ”„ åˆ‡æ¢åˆ°ç®€åŒ–ç‰ˆç”Ÿæˆä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ")
                return await run_simplified_generation(json_file, working_dir, generation_mode, data_format)
            else:
                raise
        except RuntimeError as e:
            if "event loop is already running" in str(e):
                logger.error(f"âŒ äº‹ä»¶å¾ªç¯å†²çª: {e}")
                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ç®€åŒ–ç‰ˆç”Ÿæˆ
                logger.warning("ä½¿ç”¨ç®€åŒ–ç‰ˆç”Ÿæˆä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ")
                return await run_simplified_generation(json_file, working_dir, generation_mode, data_format)
            else:
                raise
        
        # æ­¥éª¤5: å¯¼å‡ºç»Ÿè®¡ä¿¡æ¯
        final_stats_file = os.path.join(working_dir, f"final_graph_statistics_{unique_id}.json")
        graph_gen.export_graph_statistics(final_stats_file)
        
        # æ˜¾ç¤ºç»“æœ
        output_dir = os.path.join(working_dir, "data", "graphgen", str(unique_id))
        print(f"\nâœ… æ•°æ®ç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ“Š ç»Ÿè®¡æ–‡ä»¶: {final_stats_file}")
        print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
        if os.path.exists(output_dir):
            files = os.listdir(output_dir)
            if files:
                print(f"ğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶:")
                for file in files:
                    file_path = os.path.join(output_dir, file)
                    if os.path.isfile(file_path):
                        size = os.path.getsize(file_path)
                        print(f"   - {file} ({size} bytes)")
                        
                        # å¦‚æœæ˜¯ JSON æ–‡ä»¶ï¼Œæ˜¾ç¤ºå‰å‡ æ¡æ•°æ®
                        if file.endswith('.json') and size > 0:
                            try:
                                with open(file_path, 'r', encoding='utf-8') as f:
                                    data = json.load(f)
                                if isinstance(data, list) and len(data) > 0:
                                    print(f"     æ ·æœ¬æ•°é‡: {len(data)}")
                                    if len(data) > 0:
                                        sample = data[0]
                                        if isinstance(sample, dict):
                                            if 'instruction' in sample:
                                                print(f"     ç¤ºä¾‹æŒ‡ä»¤: {sample['instruction'][:100]}...")
                                            elif 'conversations' in sample:
                                                print(f"     å¯¹è¯è½®æ•°: {len(sample['conversations'])}")
                            except:
                                pass
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(description='ä½¿ç”¨ youtu-graphrag JSON çŸ¥è¯†å›¾è°±è¿è¡Œ GraphGen')
    
    # è¾“å…¥æ–‡ä»¶å‚æ•°
    parser.add_argument('--json', help='youtu-graphrag JSON æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--external-graph', help='å·²è½¬æ¢çš„ GraphML æ–‡ä»¶è·¯å¾„')
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument('--working-dir', default='cache', help='å·¥ä½œç›®å½• (é»˜è®¤: cache)')
    parser.add_argument('--converted-graph', help='è½¬æ¢åçš„å›¾è°±æ–‡ä»¶è·¯å¾„')
    
    # ç”Ÿæˆå‚æ•°
    parser.add_argument('--mode', choices=['atomic', 'aggregated', 'multi_hop', 'cot'], 
                       default='atomic', help='ç”Ÿæˆæ¨¡å¼ (é»˜è®¤: atomic)')
    parser.add_argument('--format', choices=['Alpaca', 'Sharegpt', 'ChatML'], 
                       default='Alpaca', help='æ•°æ®æ ¼å¼ (é»˜è®¤: Alpaca)')
    parser.add_argument('--quiz-samples', type=int, default=5, help='æµ‹è¯•æ ·æœ¬æ•°é‡ (é»˜è®¤: 5, è®¾ä¸º 0 ç¦ç”¨)')
    parser.add_argument('--disable-quiz', action='store_true', help='ç¦ç”¨é—®ç­”æµ‹è¯•å’Œåˆ¤æ–­æ­¥éª¤')
    parser.add_argument('--max-depth', type=int, default=3, help='æœ€å¤§éå†æ·±åº¦ (é»˜è®¤: 3)')
    parser.add_argument('--max-extra-edges', type=int, default=5, help='æœ€å¤§é¢å¤–è¾¹æ•° (é»˜è®¤: 5)')
    parser.add_argument('--enable-search', action='store_true', help='å¯ç”¨æœç´¢å¢å¼º')
    
    # æ§åˆ¶å‚æ•°
    parser.add_argument('--skip-convert', action='store_true', help='è·³è¿‡è½¬æ¢æ­¥éª¤')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not setup_environment(disable_quiz=args.disable_quiz or args.quiz_samples == 0):
        return 1
    
    # æ£€æŸ¥è¾“å…¥å‚æ•°
    if not args.skip_convert and not args.json and not args.external_graph:
        print("âŒ è¯·æä¾› --json å‚æ•°ï¼ˆyoutu-graphrag JSON æ–‡ä»¶ï¼‰æˆ– --external-graph å‚æ•°ï¼ˆå·²è½¬æ¢çš„ GraphML æ–‡ä»¶ï¼‰")
        return 1
    
    # ç¡®å®šè½¬æ¢åçš„å›¾è°±è·¯å¾„
    if args.converted_graph:
        converted_graph_path = args.converted_graph
    else:
        converted_graph_path = os.path.join(args.working_dir, "youtu_graph.graphml")
    
    # åˆ›å»ºå·¥ä½œç›®å½•
    os.makedirs(args.working_dir, exist_ok=True)
    
    # è¿è¡Œ GraphGen
    import asyncio
    
    try:
        success = asyncio.run(run_graphgen_with_youtu_json(
            json_file=args.json,
            external_graph_path=args.external_graph or converted_graph_path,
            working_dir=args.working_dir,
            generation_mode=args.mode,
            data_format=args.format,
            quiz_samples=args.quiz_samples,
            disable_quiz=args.disable_quiz,
            max_depth=args.max_depth,
            max_extra_edges=args.max_extra_edges,
            enable_search=args.enable_search,
            skip_convert=args.skip_convert
        ))
    except RuntimeError as e:
        if "event loop is already running" in str(e):
            print("âš ï¸  æ£€æµ‹åˆ°äº‹ä»¶å¾ªç¯å†²çªï¼Œä½¿ç”¨åŒæ­¥å¤‡ç”¨æ–¹æ¡ˆ...")
            # ç›´æ¥ä½¿ç”¨ç®€åŒ–ç‰ˆåŒæ­¥æ–¹æ¡ˆ
            success = run_sync_fallback(
                json_file=args.json,
                working_dir=args.working_dir,
                generation_mode=args.mode,
                data_format=args.format
            )
        else:
            raise
    
    return 0 if success else 1


def run_sync_fallback(json_file: str, working_dir: str, generation_mode: str, data_format: str):
    """åŒæ­¥å¤‡ç”¨æ–¹æ¡ˆ"""
    print("ğŸ”„ ä½¿ç”¨åŒæ­¥å¤‡ç”¨æ–¹æ¡ˆ...")
    
    try:
        # ä½¿ç”¨ç®€åŒ–ç‰ˆè½¬æ¢å™¨
        from simple_youtu_converter import SimpleYoutuConverter
        from create_qa_from_converted import create_qa_from_converted_data
        
        # 1. è½¬æ¢æ•°æ®
        converter = SimpleYoutuConverter()
        data = converter.load_youtu_json_data(json_file)
        converter.parse_youtu_data(data)
        
        converted_file = os.path.join(working_dir, "converted_data.json")
        converter.save_to_json(converted_file)
        
        # 2. ç”Ÿæˆé—®ç­”å¯¹
        qa_pairs = create_qa_from_converted_data(converted_file, data_format)
        
        # 3. ä¿å­˜ç»“æœ
        unique_id = int(time.time())
        output_dir = os.path.join(working_dir, "data", "graphgen", str(unique_id))
        os.makedirs(output_dir, exist_ok=True)
        
        output_file = os.path.join(output_dir, "qa.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(qa_pairs, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… åŒæ­¥å¤‡ç”¨æ–¹æ¡ˆæˆåŠŸï¼ç”Ÿæˆäº† {len(qa_pairs)} ä¸ªé—®ç­”å¯¹")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åŒæ­¥å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    exit(main())