#!/usr/bin/env python3
"""
youtu-graphrag çŸ¥è¯†å›¾è°±è½¬æ¢å™¨
å°† youtu-graphrag ç”Ÿæˆçš„çŸ¥è¯†å›¾è°±è½¬æ¢ä¸º GraphGen å…¼å®¹æ ¼å¼
"""

import networkx as nx
import json
import pandas as pd
import argparse
import os
from typing import Dict, Any, List, Union
from pathlib import Path


class YoutuGraphRAGConverter:
    """å°† youtu-graphrag çŸ¥è¯†å›¾è°±è½¬æ¢ä¸º GraphGen æ ¼å¼"""
    
    def __init__(self):
        self.graph = nx.Graph()
        self.entity_mapping = {}  # ç”¨äºå¤„ç†å®ä½“åç§°æ˜ å°„
    
    def load_youtu_graphrag_data(self, entities_file: str, relationships_file: str):
        """
        åŠ è½½ youtu-graphrag ç”Ÿæˆçš„å®ä½“å’Œå…³ç³»æ•°æ®
        
        Args:
            entities_file: å®ä½“æ–‡ä»¶è·¯å¾„ (æ”¯æŒ CSV, JSON, JSONL)
            relationships_file: å…³ç³»æ–‡ä»¶è·¯å¾„ (æ”¯æŒ CSV, JSON, JSONL)
        """
        print(f"æ­£åœ¨åŠ è½½å®ä½“æ•°æ®: {entities_file}")
        entities_df = self._load_file(entities_file)
        
        print(f"æ­£åœ¨åŠ è½½å…³ç³»æ•°æ®: {relationships_file}")
        relationships_df = self._load_file(relationships_file)
        
        print(f"åŠ è½½å®Œæˆ - å®ä½“: {len(entities_df)}, å…³ç³»: {len(relationships_df)}")
        return entities_df, relationships_df
    
    def _load_file(self, file_path: str) -> pd.DataFrame:
        """åŠ è½½ä¸åŒæ ¼å¼çš„æ–‡ä»¶"""
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        file_ext = Path(file_path).suffix.lower()
        
        if file_ext == '.csv':
            return pd.read_csv(file_path, encoding='utf-8')
        elif file_ext == '.json':
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            if isinstance(data, list):
                return pd.DataFrame(data)
            elif isinstance(data, dict):
                # å¦‚æœæ˜¯åµŒå¥—å­—å…¸ï¼Œå°è¯•å±•å¹³
                return pd.DataFrame([data])
        elif file_ext == '.jsonl':
            data = []
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        data.append(json.loads(line))
            return pd.DataFrame(data)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
    
    def _normalize_entity_id(self, entity_data: pd.Series) -> str:
        """æ ‡å‡†åŒ–å®ä½“ID"""
        # å°è¯•ä¸åŒçš„å­—æ®µå
        possible_id_fields = ['id', 'entity_id', 'name', 'entity_name', 'title']
        
        for field in possible_id_fields:
            if field in entity_data and pd.notna(entity_data[field]):
                return str(entity_data[field]).strip()
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„IDï¼Œä½¿ç”¨ç´¢å¼•
        return f"entity_{entity_data.name}"
    
    def _normalize_entity_type(self, entity_data: pd.Series) -> str:
        """æ ‡å‡†åŒ–å®ä½“ç±»å‹"""
        possible_type_fields = ['type', 'entity_type', 'category', 'class']
        
        for field in possible_type_fields:
            if field in entity_data and pd.notna(entity_data[field]):
                return str(entity_data[field]).strip()
        
        return "unknown"
    
    def _normalize_entity_description(self, entity_data: pd.Series) -> str:
        """æ ‡å‡†åŒ–å®ä½“æè¿°"""
        possible_desc_fields = ['description', 'summary', 'content', 'text', 'details']
        
        for field in possible_desc_fields:
            if field in entity_data and pd.notna(entity_data[field]):
                return str(entity_data[field]).strip()
        
        return ""
    
    def _normalize_relationship_data(self, relation_data: pd.Series) -> tuple:
        """æ ‡å‡†åŒ–å…³ç³»æ•°æ®"""
        # æºå®ä½“
        source_fields = ['source', 'src_id', 'source_entity', 'from', 'subject']
        source = None
        for field in source_fields:
            if field in relation_data and pd.notna(relation_data[field]):
                source = str(relation_data[field]).strip()
                break
        
        # ç›®æ ‡å®ä½“
        target_fields = ['target', 'tgt_id', 'target_entity', 'to', 'object']
        target = None
        for field in target_fields:
            if field in relation_data and pd.notna(relation_data[field]):
                target = str(relation_data[field]).strip()
                break
        
        # å…³ç³»æè¿°
        desc_fields = ['description', 'relationship_summary', 'relation', 'predicate', 'label']
        description = ""
        for field in desc_fields:
            if field in relation_data and pd.notna(relation_data[field]):
                description = str(relation_data[field]).strip()
                break
        
        # æƒé‡
        weight_fields = ['weight', 'strength', 'confidence', 'score']
        weight = 1.0
        for field in weight_fields:
            if field in relation_data and pd.notna(relation_data[field]):
                try:
                    weight = float(relation_data[field])
                    break
                except (ValueError, TypeError):
                    continue
        
        return source, target, description, weight
    
    def convert_to_graphgen_format(self, entities_df: pd.DataFrame, relationships_df: pd.DataFrame):
        """
        è½¬æ¢ä¸º GraphGen å…¼å®¹çš„æ ¼å¼
        """
        print("å¼€å§‹è½¬æ¢å®ä½“æ•°æ®...")
        
        # æ·»åŠ èŠ‚ç‚¹
        for idx, entity in entities_df.iterrows():
            node_id = self._normalize_entity_id(entity)
            entity_type = self._normalize_entity_type(entity)
            description = self._normalize_entity_description(entity)
            
            # å­˜å‚¨å®ä½“æ˜ å°„
            self.entity_mapping[node_id] = node_id
            
            node_data = {
                'entity_name': node_id,
                'entity_type': entity_type,
                'description': description,
                'source_id': 'youtu_graphrag'
            }
            
            # æ·»åŠ å…¶ä»–å¯èƒ½çš„å±æ€§
            for col in entity.index:
                if col not in ['id', 'entity_id', 'name', 'entity_name', 'type', 'entity_type', 'description', 'summary']:
                    if pd.notna(entity[col]):
                        node_data[f'extra_{col}'] = str(entity[col])
            
            self.graph.add_node(node_id, **node_data)
        
        print(f"å·²æ·»åŠ  {self.graph.number_of_nodes()} ä¸ªèŠ‚ç‚¹")
        print("å¼€å§‹è½¬æ¢å…³ç³»æ•°æ®...")
        
        # æ·»åŠ è¾¹
        valid_edges = 0
        for idx, relation in relationships_df.iterrows():
            source, target, description, weight = self._normalize_relationship_data(relation)
            
            if not source or not target:
                print(f"è·³è¿‡æ— æ•ˆå…³ç³» (è¡Œ {idx}): source={source}, target={target}")
                continue
            
            # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨
            if not self.graph.has_node(source):
                print(f"è­¦å‘Š: æºèŠ‚ç‚¹ä¸å­˜åœ¨ï¼Œåˆ›å»ºèŠ‚ç‚¹: {source}")
                self.graph.add_node(source, entity_name=source, entity_type="unknown", 
                                  description="", source_id="youtu_graphrag_missing")
            
            if not self.graph.has_node(target):
                print(f"è­¦å‘Š: ç›®æ ‡èŠ‚ç‚¹ä¸å­˜åœ¨ï¼Œåˆ›å»ºèŠ‚ç‚¹: {target}")
                self.graph.add_node(target, entity_name=target, entity_type="unknown", 
                                  description="", source_id="youtu_graphrag_missing")
            
            edge_data = {
                'weight': weight,
                'description': description,
                'source_id': 'youtu_graphrag'
            }
            
            # æ·»åŠ å…¶ä»–å¯èƒ½çš„å±æ€§
            for col in relation.index:
                if col not in ['source', 'target', 'src_id', 'tgt_id', 'description', 'weight']:
                    if pd.notna(relation[col]):
                        edge_data[f'extra_{col}'] = str(relation[col])
            
            self.graph.add_edge(source, target, **edge_data)
            valid_edges += 1
        
        print(f"å·²æ·»åŠ  {valid_edges} æ¡æœ‰æ•ˆè¾¹")
    
    def save_to_graphml(self, output_file: str):
        """ä¿å­˜ä¸º GraphML æ ¼å¼"""
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        # ç¡®ä¿æ‰€æœ‰å±æ€§éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼ˆGraphML è¦æ±‚ï¼‰
        for node_id, node_data in self.graph.nodes(data=True):
            for key, value in node_data.items():
                node_data[key] = str(value)
        
        for source, target, edge_data in self.graph.edges(data=True):
            for key, value in edge_data.items():
                edge_data[key] = str(value)
        
        nx.write_graphml(self.graph, output_file, encoding='utf-8')
        print(f"\nâœ… çŸ¥è¯†å›¾è°±è½¬æ¢å®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - èŠ‚ç‚¹æ•°: {self.graph.number_of_nodes()}")
        print(f"   - è¾¹æ•°: {self.graph.number_of_edges()}")
        
        # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹èŠ‚ç‚¹å’Œè¾¹
        if self.graph.number_of_nodes() > 0:
            print(f"\nğŸ“ ç¤ºä¾‹èŠ‚ç‚¹:")
            for i, (node_id, node_data) in enumerate(self.graph.nodes(data=True)):
                if i >= 3:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    break
                print(f"   - {node_id}: {node_data.get('entity_type', 'unknown')} - {node_data.get('description', '')[:50]}...")
        
        if self.graph.number_of_edges() > 0:
            print(f"\nğŸ”— ç¤ºä¾‹å…³ç³»:")
            for i, (source, target, edge_data) in enumerate(self.graph.edges(data=True)):
                if i >= 3:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    break
                print(f"   - {source} -> {target}: {edge_data.get('description', '')[:50]}...")
    
    def validate_graph(self):
        """éªŒè¯è½¬æ¢åçš„å›¾è°±"""
        issues = []
        
        # æ£€æŸ¥å­¤ç«‹èŠ‚ç‚¹
        isolated_nodes = list(nx.isolates(self.graph))
        if isolated_nodes:
            issues.append(f"å‘ç° {len(isolated_nodes)} ä¸ªå­¤ç«‹èŠ‚ç‚¹")
        
        # æ£€æŸ¥èŠ‚ç‚¹å±æ€§
        nodes_without_description = 0
        for node_id, node_data in self.graph.nodes(data=True):
            if not node_data.get('description', '').strip():
                nodes_without_description += 1
        
        if nodes_without_description > 0:
            issues.append(f"{nodes_without_description} ä¸ªèŠ‚ç‚¹ç¼ºå°‘æè¿°")
        
        # æ£€æŸ¥è¾¹å±æ€§
        edges_without_description = 0
        for source, target, edge_data in self.graph.edges(data=True):
            if not edge_data.get('description', '').strip():
                edges_without_description += 1
        
        if edges_without_description > 0:
            issues.append(f"{edges_without_description} æ¡è¾¹ç¼ºå°‘æè¿°")
        
        if issues:
            print(f"\nâš ï¸  éªŒè¯å‘ç°çš„é—®é¢˜:")
            for issue in issues:
                print(f"   - {issue}")
        else:
            print(f"\nâœ… å›¾è°±éªŒè¯é€šè¿‡ï¼Œæ²¡æœ‰å‘ç°é—®é¢˜")


def main():
    parser = argparse.ArgumentParser(description='å°† youtu-graphrag çŸ¥è¯†å›¾è°±è½¬æ¢ä¸º GraphGen æ ¼å¼')
    parser.add_argument('--entities', required=True, help='å®ä½“æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--relationships', required=True, help='å…³ç³»æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', required=True, help='è¾“å‡º GraphML æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--validate', action='store_true', help='éªŒè¯è½¬æ¢åçš„å›¾è°±')
    
    args = parser.parse_args()
    
    try:
        converter = YoutuGraphRAGConverter()
        entities_df, relationships_df = converter.load_youtu_graphrag_data(
            args.entities, args.relationships
        )
        converter.convert_to_graphgen_format(entities_df, relationships_df)
        
        if args.validate:
            converter.validate_graph()
        
        converter.save_to_graphml(args.output)
        
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())