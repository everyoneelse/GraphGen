"""
é›†æˆè°ƒè¯•å™¨çš„ç¤ºä¾‹è„šæœ¬

å±•ç¤ºå¦‚ä½•å°†NodeEdgeDebuggeré›†æˆåˆ°ç°æœ‰çš„graphgenæµç¨‹ä¸­
"""

import sys
import os

# æ–¹æ¡ˆ1: é€šè¿‡Monkey Patchingçš„æ–¹å¼é›†æˆè°ƒè¯•å™¨ï¼ˆæ— éœ€ä¿®æ”¹æºä»£ç ï¼‰
def patch_split_kg_with_debugger():
    """
    é€šè¿‡monkey patchingçš„æ–¹å¼ç»™split_kgæ·»åŠ è°ƒè¯•åŠŸèƒ½
    è¿™ç§æ–¹å¼ä¸éœ€è¦ä¿®æ”¹æºä»£ç 
    """
    from graphgen.operators.build_kg import split_kg
    from debug_node_edge_selection import NodeEdgeDebugger
    
    # ä¿å­˜åŸå§‹å‡½æ•°
    original_get_batches = split_kg.get_batches_with_strategy
    
    # åˆ›å»ºè°ƒè¯•å™¨å®ä¾‹
    debugger = NodeEdgeDebugger(output_dir="./debug_output")
    
    # åŒ…è£…åŸå§‹å‡½æ•°
    async def wrapped_get_batches(nodes, edges, graph_storage, traverse_strategy):
        # è®°å½•å›¾ä¿¡æ¯
        debugger.record_graph_info(nodes, edges)
        print("\nğŸ” è°ƒè¯•æ¨¡å¼å·²å¯ç”¨ï¼Œæ­£åœ¨ç›‘æ§nodeå’Œedgeé€‰å–è¿‡ç¨‹...")
        
        # è°ƒç”¨åŸå§‹å‡½æ•°
        processing_batches = await original_get_batches(
            nodes, edges, graph_storage, traverse_strategy
        )
        
        # è®°å½•æ¯ä¸ªbatch
        for i, (batch_nodes, batch_edges) in enumerate(processing_batches):
            debugger.record_batch(i, batch_nodes, batch_edges, traverse_strategy)
        
        # ç”ŸæˆæŠ¥å‘Š
        print("\nğŸ“Š ç”Ÿæˆè°ƒè¯•æŠ¥å‘Š...")
        stats = debugger.generate_report()
        
        return processing_batches
    
    # æ›¿æ¢åŸå§‹å‡½æ•°
    split_kg.get_batches_with_strategy = wrapped_get_batches
    print("âœ… è°ƒè¯•å™¨å·²é€šè¿‡monkey patchingæ–¹å¼é›†æˆ")


# æ–¹æ¡ˆ2: åˆ›å»ºè‡ªå®šä¹‰çš„generateå‡½æ•°
def run_generate_with_debug(config_file: str, output_dir: str):
    """
    è¿è¡Œå¸¦è°ƒè¯•åŠŸèƒ½çš„generateæµç¨‹
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
    """
    import yaml
    from graphgen.graphgen import GraphGen
    from graphgen.utils import set_logger, logger
    import time
    
    # é¦–å…ˆé›†æˆè°ƒè¯•å™¨
    patch_split_kg_with_debugger()
    
    # åŠ è½½é…ç½®
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.load(f, Loader=yaml.FullLoader)
    
    mode = config["generate"]["mode"]
    unique_id = int(time.time())
    
    output_path = os.path.join(output_dir, "data", "graphgen", f"{unique_id}")
    os.makedirs(output_path, exist_ok=True)
    
    set_logger(
        os.path.join(output_path, f"{unique_id}_{mode}.log"),
        if_stream=True,
    )
    
    logger.info("ğŸ› è°ƒè¯•æ¨¡å¼: å¯åŠ¨GraphGen with debug")
    
    # åˆ›å»ºGraphGenå®ä¾‹
    graph_gen = GraphGen(unique_id=unique_id, working_dir=output_dir)
    
    # æ‰§è¡Œæµç¨‹
    graph_gen.insert(read_config=config["read"], split_config=config["split"])
    graph_gen.search(search_config=config["search"])
    
    # æ ¹æ®æ¨¡å¼æ‰§è¡Œ
    if mode in ["atomic", "aggregated", "multi_hop"]:
        if "quiz_and_judge" in config and config["quiz_and_judge"]["enabled"]:
            graph_gen.quiz_and_judge(quiz_and_judge_config=config["quiz_and_judge"])
        else:
            logger.warning("Quiz and Judge disabled, edge sampling fallback to random")
            config["partition"]["method_params"]["edge_sampling"] = "random"
    
    # ç”Ÿæˆï¼ˆè¿™é‡Œä¼šè°ƒç”¨è¢«patchedçš„å‡½æ•°ï¼‰
    graph_gen.generate(
        partition_config=config["partition"],
        generate_config=config["generate"],
    )
    
    logger.info("âœ… GraphGen completed with debug info at %s", output_path)
    logger.info("ğŸ“ Debug reports saved to ./debug_output/")


# æ–¹æ¡ˆ3: ä»…åˆ†æå·²æœ‰çš„batchæ•°æ®ï¼ˆäº‹ååˆ†æï¼‰
def analyze_existing_batch_data(batch_file: str):
    """
    åˆ†æå·²ç»ä¿å­˜çš„batchæ•°æ®
    
    Args:
        batch_file: batchæ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰
    """
    import json
    from debug_node_edge_selection import NodeEdgeDebugger
    
    print(f"ğŸ“– è¯»å–batchæ•°æ®: {batch_file}")
    
    with open(batch_file, 'r', encoding='utf-8') as f:
        batch_data = json.load(f)
    
    debugger = NodeEdgeDebugger(output_dir="./analysis_output")
    
    # æ‰‹åŠ¨æ„å»ºæ•°æ®
    all_nodes = set()
    all_edges = set()
    
    for i, batch in enumerate(batch_data):
        nodes = [{'node_id': nid} for nid in batch['node_ids']]
        edges = [(ep.split(' -> ')[0], ep.split(' -> ')[1], {}) 
                 for ep in batch['edge_pairs']]
        
        all_nodes.update(batch['node_ids'])
        all_edges.update([tuple(ep.split(' -> ')) for ep in batch['edge_pairs']])
        
        debugger.record_batch(i, nodes, edges)
    
    # è®¾ç½®æ€»æ•°
    debugger.total_nodes = len(all_nodes)
    debugger.total_edges = len(all_edges)
    
    # ç”ŸæˆæŠ¥å‘Š
    stats = debugger.generate_report()
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼ŒæŠ¥å‘Šä¿å­˜åœ¨ ./analysis_output/")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Node/Edgeé€‰å–è°ƒè¯•å·¥å…·é›†æˆè„šæœ¬")
    parser.add_argument(
        "--mode",
        choices=["run", "analyze"],
        default="run",
        help="è¿è¡Œæ¨¡å¼: run=è¿è¡Œå¸¦è°ƒè¯•çš„generate, analyze=åˆ†æå·²æœ‰æ•°æ®"
    )
    parser.add_argument(
        "--config",
        type=str,
        default="graphgen/configs/aggregated_config.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„ (runæ¨¡å¼ä½¿ç”¨)"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="./",
        help="è¾“å‡ºç›®å½• (runæ¨¡å¼ä½¿ç”¨)"
    )
    parser.add_argument(
        "--batch_file",
        type=str,
        help="batchæ•°æ®æ–‡ä»¶è·¯å¾„ (analyzeæ¨¡å¼ä½¿ç”¨)"
    )
    
    args = parser.parse_args()
    
    if args.mode == "run":
        print("=" * 80)
        print("å¯åŠ¨è°ƒè¯•æ¨¡å¼è¿è¡ŒGraphGen")
        print("=" * 80)
        run_generate_with_debug(args.config, args.output_dir)
        
    elif args.mode == "analyze":
        if not args.batch_file:
            print("âŒ analyzeæ¨¡å¼éœ€è¦æä¾› --batch_file å‚æ•°")
            sys.exit(1)
        
        print("=" * 80)
        print("åˆ†æå·²æœ‰batchæ•°æ®")
        print("=" * 80)
        analyze_existing_batch_data(args.batch_file)
