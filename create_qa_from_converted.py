#!/usr/bin/env python3
"""
ä»è½¬æ¢åçš„ youtu-graphrag æ•°æ®åˆ›å»ºé—®ç­”å¯¹
"""

import json
import argparse
import os


def create_qa_from_converted_data(json_file: str, output_format: str = "Alpaca"):
    """ä»è½¬æ¢åçš„æ•°æ®åˆ›å»ºé—®ç­”å¯¹"""
    
    print(f"ğŸ“– è¯»å–è½¬æ¢åçš„æ•°æ®: {json_file}")
    
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    qa_pairs = []
    
    print(f"ğŸ”„ å¼€å§‹ç”Ÿæˆé—®ç­”å¯¹...")
    
    # ä»èŠ‚ç‚¹åˆ›å»ºå±æ€§é—®ç­”
    for node in data['nodes']:
        entity_name = node['entity_name']
        description = node['description']
        entity_type = node['entity_type']
        
        # 1. ç±»å‹é—®ç­”
        if output_format == "Alpaca":
            qa_pairs.append({
                "instruction": f"What type of entity is {entity_name}?",
                "input": "",
                "output": f"{entity_name} is a {entity_type}."
            })
        elif output_format == "Sharegpt":
            qa_pairs.append({
                "conversations": [
                    {"from": "human", "value": f"What type of entity is {entity_name}?"},
                    {"from": "gpt", "value": f"{entity_name} is a {entity_type}."}
                ]
            })
        elif output_format == "ChatML":
            qa_pairs.append({
                "messages": [
                    {"role": "user", "content": f"What type of entity is {entity_name}?"},
                    {"role": "assistant", "content": f"{entity_name} is a {entity_type}."}
                ]
            })
        
        # 2. å±æ€§é—®ç­”
        if ";" in description:
            attributes = description.split(";")[1:]  # è·³è¿‡ "Type: xxx"
            if attributes:
                attr_text = ', '.join(attr.strip() for attr in attributes)
                
                if output_format == "Alpaca":
                    qa_pairs.append({
                        "instruction": f"What are the attributes of {entity_name}?",
                        "input": "",
                        "output": f"{entity_name} has the following attributes: {attr_text}."
                    })
                elif output_format == "Sharegpt":
                    qa_pairs.append({
                        "conversations": [
                            {"from": "human", "value": f"What are the attributes of {entity_name}?"},
                            {"from": "gpt", "value": f"{entity_name} has the following attributes: {attr_text}."}
                        ]
                    })
                elif output_format == "ChatML":
                    qa_pairs.append({
                        "messages": [
                            {"role": "user", "content": f"What are the attributes of {entity_name}?"},
                            {"role": "assistant", "content": f"{entity_name} has the following attributes: {attr_text}."}
                        ]
                    })
    
    # ä»è¾¹åˆ›å»ºå…³ç³»é—®ç­”
    for edge in data['edges']:
        source = edge['source']
        target = edge['target']
        relation = edge['relation_type']
        
        if output_format == "Alpaca":
            qa_pairs.append({
                "instruction": f"What is the relationship between {source} and {target}?",
                "input": "",
                "output": f"{source} {relation} {target}."
            })
        elif output_format == "Sharegpt":
            qa_pairs.append({
                "conversations": [
                    {"from": "human", "value": f"What is the relationship between {source} and {target}?"},
                    {"from": "gpt", "value": f"{source} {relation} {target}."}
                ]
            })
        elif output_format == "ChatML":
            qa_pairs.append({
                "messages": [
                    {"role": "user", "content": f"What is the relationship between {source} and {target}?"},
                    {"role": "assistant", "content": f"{source} {relation} {target}."}
                ]
            })
    
    # åˆ›å»ºå¤åˆé—®ç­”ï¼ˆå¤šè·³æ¨ç†ï¼‰
    if len(data['edges']) >= 2:
        # å¯»æ‰¾å¯ä»¥è¿æ¥çš„å…³ç³»é“¾
        entity_connections = {}
        for edge in data['edges']:
            source = edge['source']
            target = edge['target']
            relation = edge['relation_type']
            
            if source not in entity_connections:
                entity_connections[source] = []
            entity_connections[source].append((target, relation))
        
        # ç”Ÿæˆå¤šè·³é—®ç­”
        for entity, connections in entity_connections.items():
            if len(connections) > 0:
                # åˆ›å»ºä¸€ä¸ªç»¼åˆé—®é¢˜
                connected_entities = [conn[0] for conn in connections]
                relations_text = ', '.join([f"{conn[1]} {conn[0]}" for conn in connections])
                
                if output_format == "Alpaca":
                    qa_pairs.append({
                        "instruction": f"What entities are connected to {entity} and how?",
                        "input": "",
                        "output": f"{entity} is connected to the following entities: {relations_text}."
                    })
                elif output_format == "Sharegpt":
                    qa_pairs.append({
                        "conversations": [
                            {"from": "human", "value": f"What entities are connected to {entity} and how?"},
                            {"from": "gpt", "value": f"{entity} is connected to the following entities: {relations_text}."}
                        ]
                    })
                elif output_format == "ChatML":
                    qa_pairs.append({
                        "messages": [
                            {"role": "user", "content": f"What entities are connected to {entity} and how?"},
                            {"role": "assistant", "content": f"{entity} is connected to the following entities: {relations_text}."}
                        ]
                    })
    
    print(f"âœ… ç”Ÿæˆäº† {len(qa_pairs)} ä¸ªé—®ç­”å¯¹")
    return qa_pairs


def main():
    parser = argparse.ArgumentParser(description='ä»è½¬æ¢åçš„æ•°æ®åˆ›å»ºé—®ç­”å¯¹')
    parser.add_argument('--input', required=True, help='è½¬æ¢åçš„ JSON æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', required=True, help='è¾“å‡ºé—®ç­”æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--format', choices=['Alpaca', 'Sharegpt', 'ChatML'], 
                       default='Alpaca', help='è¾“å‡ºæ ¼å¼ (é»˜è®¤: Alpaca)')
    
    args = parser.parse_args()
    
    try:
        # ç”Ÿæˆé—®ç­”å¯¹
        qa_pairs = create_qa_from_converted_data(args.input, args.format)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(args.output), exist_ok=True)
        
        # ä¿å­˜é—®ç­”å¯¹
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(qa_pairs, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“ é—®ç­”å¯¹å·²ä¿å­˜åˆ°: {args.output}")
        print(f"ğŸ“Š æ ¼å¼: {args.format}")
        print(f"ğŸ“ˆ æ•°é‡: {len(qa_pairs)}")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªç¤ºä¾‹
        print(f"\nğŸ“ ç¤ºä¾‹é—®ç­”å¯¹:")
        for i, qa in enumerate(qa_pairs[:3]):
            print(f"\n{i+1}. ", end="")
            if args.format == "Alpaca":
                print(f"Q: {qa['instruction']}")
                print(f"   A: {qa['output']}")
            elif args.format == "Sharegpt":
                conv = qa['conversations']
                print(f"Q: {conv[0]['value']}")
                print(f"   A: {conv[1]['value']}")
            elif args.format == "ChatML":
                msgs = qa['messages']
                print(f"Q: {msgs[0]['content']}")
                print(f"   A: {msgs[1]['content']}")
        
        if len(qa_pairs) > 3:
            print(f"\n... è¿˜æœ‰ {len(qa_pairs) - 3} ä¸ªé—®ç­”å¯¹")
        
        print(f"\nğŸ‰ é—®ç­”å¯¹ç”Ÿæˆå®Œæˆï¼å¯ä»¥ç›´æ¥ç”¨äºæ¨¡å‹è®­ç»ƒã€‚")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())