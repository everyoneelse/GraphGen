#!/usr/bin/env python3
"""
æµ‹è¯• youtu-graphrag chunks æ–‡ä»¶åŠ è½½åŠŸèƒ½
"""

import sys
import os
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from youtu_json_converter import YoutuJSONConverter


def test_chunks_loading(chunks_file: str):
    """æµ‹è¯• chunks æ–‡ä»¶åŠ è½½"""
    print("=" * 70)
    print("æµ‹è¯• Youtu-GraphRAG Chunks æ–‡ä»¶åŠ è½½")
    print("=" * 70)
    
    # 1. åˆ›å»ºè½¬æ¢å™¨
    print("\nğŸ“ æ­¥éª¤ 1: åˆ›å»ºè½¬æ¢å™¨")
    converter = YoutuJSONConverter()
    
    # 2. åŠ è½½ chunks æ–‡ä»¶
    print(f"\nğŸ“„ æ­¥éª¤ 2: åŠ è½½ chunks æ–‡ä»¶: {chunks_file}")
    try:
        chunks_count = converter.load_youtu_chunks(chunks_file)
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {chunks_file}")
        return False
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    if chunks_count == 0:
        print("âš ï¸  è­¦å‘Š: æ²¡æœ‰åŠ è½½åˆ°ä»»ä½• chunks")
        print("   å¯èƒ½åŸå› :")
        print("   - æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
        print("   - æ–‡ä»¶ä¸ºç©º")
        print("   - è§£æé”™è¯¯")
        return False
    
    print(f"âœ… æˆåŠŸåŠ è½½ {chunks_count} ä¸ª chunks")
    
    # 3. æ˜¾ç¤º chunks ç»Ÿè®¡
    print("\nğŸ“Š æ­¥éª¤ 3: Chunks ç»Ÿè®¡")
    chunks_dict = converter.get_chunks_dict()
    
    # ç»Ÿè®¡å­—æ®µ
    has_title = sum(1 for c in chunks_dict.values() if c.get('title'))
    has_content = sum(1 for c in chunks_dict.values() if c.get('content'))
    has_source = sum(1 for c in chunks_dict.values() if c.get('source'))
    
    print(f"   æ€» chunks æ•°: {len(chunks_dict)}")
    print(f"   åŒ…å«æ ‡é¢˜: {has_title} ({has_title/len(chunks_dict)*100:.1f}%)")
    print(f"   åŒ…å«å†…å®¹: {has_content} ({has_content/len(chunks_dict)*100:.1f}%)")
    print(f"   åŒ…å«æ¥æº: {has_source} ({has_source/len(chunks_dict)*100:.1f}%)")
    
    # ç»Ÿè®¡å†…å®¹é•¿åº¦
    content_lengths = [len(c.get('content', '')) for c in chunks_dict.values()]
    if content_lengths:
        avg_length = sum(content_lengths) / len(content_lengths)
        min_length = min(content_lengths)
        max_length = max(content_lengths)
        
        print(f"\n   å†…å®¹é•¿åº¦ç»Ÿè®¡:")
        print(f"     å¹³å‡: {avg_length:.0f} å­—ç¬¦")
        print(f"     æœ€çŸ­: {min_length} å­—ç¬¦")
        print(f"     æœ€é•¿: {max_length} å­—ç¬¦")
    
    # 4. æ˜¾ç¤ºç¤ºä¾‹ chunks
    print("\nğŸ“ æ­¥éª¤ 4: ç¤ºä¾‹ Chunksï¼ˆå‰3ä¸ªï¼‰")
    for i, (chunk_id, chunk_data) in enumerate(list(chunks_dict.items())[:3]):
        print(f"\n   Chunk {i+1}: {chunk_id}")
        
        if 'title' in chunk_data and chunk_data['title']:
            print(f"   æ ‡é¢˜: {chunk_data['title'][:60]}...")
        
        if 'content' in chunk_data and chunk_data['content']:
            content_preview = chunk_data['content'][:150].replace('\n', ' ')
            print(f"   å†…å®¹: {content_preview}...")
        
        if 'source' in chunk_data and chunk_data['source']:
            print(f"   æ¥æº: {chunk_data['source']}")
    
    # 5. æµ‹è¯•å¯¼å‡ºåŠŸèƒ½
    print("\nğŸ’¾ æ­¥éª¤ 5: æµ‹è¯•å¯¼å‡ºåŠŸèƒ½")
    test_output = "test_chunks_output.json"
    try:
        converter.export_chunks(test_output)
        print(f"âœ… Chunks å·²å¯¼å‡ºåˆ°: {test_output}")
        
        # éªŒè¯æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(test_output)
        print(f"   æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚ ({file_size/1024:.1f} KB)")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        print(f"   ä¿ç•™æµ‹è¯•æ–‡ä»¶ä¾›æ£€æŸ¥: {test_output}")
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        return False
    
    # 6. æ£€æŸ¥ chunk IDs æ ¼å¼
    print("\nğŸ” æ­¥éª¤ 6: æ£€æŸ¥ Chunk IDs æ ¼å¼")
    chunk_ids = list(chunks_dict.keys())
    
    # æ˜¾ç¤º ID æ ·ä¾‹
    print(f"   ç¤ºä¾‹ IDs: {', '.join(chunk_ids[:5])}")
    
    # æ£€æŸ¥ ID é•¿åº¦åˆ†å¸ƒ
    id_lengths = [len(cid) for cid in chunk_ids]
    from collections import Counter
    length_dist = Counter(id_lengths)
    
    print(f"\n   ID é•¿åº¦åˆ†å¸ƒ:")
    for length, count in sorted(length_dist.items())[:5]:
        print(f"     é•¿åº¦ {length}: {count} ä¸ª")
    
    # 7. æ€»ç»“
    print("\n" + "=" * 70)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“")
    print("=" * 70)
    
    if chunks_count >= 10 and has_content == len(chunks_dict):
        print("âœ… Chunks æ–‡ä»¶è´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥ç”¨äºæ·»åŠ æ–‡æ¡£ä¸Šä¸‹æ–‡")
    elif chunks_count >= 5:
        print("âš ï¸  Chunks æ–‡ä»¶è´¨é‡è‰¯å¥½ï¼Œä½†æ•°é‡è¾ƒå°‘")
    else:
        print("âŒ Chunks æ–‡ä»¶è´¨é‡è¾ƒå·®æˆ–æ•°é‡å¤ªå°‘")
    
    print(f"\nä½¿ç”¨æ–¹æ³•:")
    print(f"  python run_youtu_json_kg.py \\")
    print(f"    --json your_graph.json \\")
    print(f"    --chunks {chunks_file} \\")
    print(f"    --mode cot \\")
    print(f"    --add-context \\")
    print(f"    --disable-quiz")
    
    print(f"\nğŸ’¡ æç¤º:")
    print(f"  - å¯¼å‡ºçš„ JSON æ–‡ä»¶ä½äº: {test_output}")
    print(f"  - å¯ä»¥ç”¨ jq æˆ–æ–‡æœ¬ç¼–è¾‘å™¨æŸ¥çœ‹å†…å®¹")
    print(f"  - å‘½ä»¤: cat {test_output} | jq '.' | less")
    
    return True


def create_sample_chunks_file():
    """åˆ›å»ºç¤ºä¾‹ chunks æ–‡ä»¶ç”¨äºæµ‹è¯•"""
    sample_file = "sample_chunks.txt"
    
    sample_content = """id: chunk_001	Chunk: {'title': 'æµ‹è¯•æ ‡é¢˜1', 'content': 'è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•chunkçš„å†…å®¹ã€‚å®ƒåŒ…å«äº†ä¸€äº›ç¤ºä¾‹æ–‡æœ¬ã€‚', 'source': 'test_source.md'}
id: chunk_002	Chunk: {'title': 'æµ‹è¯•æ ‡é¢˜2', 'content': 'è¿™æ˜¯ç¬¬äºŒä¸ªæµ‹è¯•chunkçš„å†…å®¹ã€‚\\nå®ƒå¯ä»¥åŒ…å«å¤šè¡Œã€‚\\næ¯è¡Œéƒ½æ˜¯å†…å®¹çš„ä¸€éƒ¨åˆ†ã€‚', 'source': 'test_source.md'}
id: chunk_003	Chunk: {'title': '', 'content': 'æ²¡æœ‰æ ‡é¢˜çš„chunkä¹Ÿæ˜¯å¯ä»¥çš„ã€‚åªè¦æœ‰å†…å®¹å°±è¡Œã€‚', 'source': 'another_source.txt'}
"""
    
    with open(sample_file, 'w', encoding='utf-8') as f:
        f.write(sample_content)
    
    print(f"âœ… å·²åˆ›å»ºç¤ºä¾‹ chunks æ–‡ä»¶: {sample_file}")
    print(f"   åŒ…å« 3 ä¸ªç¤ºä¾‹ chunks")
    print(f"\nå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æµ‹è¯•:")
    print(f"  python test_chunks_loading.py --chunks {sample_file}")
    
    return sample_file


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='æµ‹è¯• youtu-graphrag chunks æ–‡ä»¶åŠ è½½')
    parser.add_argument('--chunks', help='youtu-graphrag chunks æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--create-sample', action='store_true', 
                       help='åˆ›å»ºç¤ºä¾‹ chunks æ–‡ä»¶å¹¶æµ‹è¯•')
    
    args = parser.parse_args()
    
    if args.create_sample:
        sample_file = create_sample_chunks_file()
        print("\n" + "=" * 70)
        print("æµ‹è¯•ç¤ºä¾‹æ–‡ä»¶")
        print("=" * 70)
        success = test_chunks_loading(sample_file)
    elif args.chunks:
        success = test_chunks_loading(args.chunks)
    else:
        parser.print_help()
        print("\nç¤ºä¾‹ç”¨æ³•:")
        print("  1. æµ‹è¯•çœŸå®æ–‡ä»¶:")
        print("     python test_chunks_loading.py --chunks path/to/text")
        print("\n  2. åˆ›å»ºå¹¶æµ‹è¯•ç¤ºä¾‹æ–‡ä»¶:")
        print("     python test_chunks_loading.py --create-sample")
        return 1
    
    return 0 if success else 1


if __name__ == "__main__":
    exit(main())
